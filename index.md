# hi!
<br><br>
### Me- for those in a rush
I’m a PhD candidate at [Goldsmiths UoL](https://www.gold.ac.uk/), (part of [IGGI CDT](http://www.iggi.org.uk/)) exploring the nonverbal behaviour of virtual humans in [6DoF](https://en.wikipedia.org/wiki/Six_degrees_of_freedom) VR, aiming towards autonomous virtual humans. I’m supervised by [Sylvia (Xueni) Pan](www.panxueni.com) and [Marco Gillies](https://www.gold.ac.uk/computing/people/m-gillies/). 
I’ve had research positions at [Microsoft Research Cambridge](https://www.microsoft.com/en-us/research/theme/future-of-work/) (with [Sean Rintel](https://www.microsoft.com/en-us/research/people/serintel/) and [Marta Wilczkowiak](https://www.linkedin.com/in/marta-wilczkowiak-716b772/)) and [Dream Reality Interactive](https://www.dreamrealityinteractive.com/) (with [Dave Ranyard](https://www.linkedin.com/in/daveranyard)). 

I’ve published my work in [Springer VR journal](https://www.springer.com/journal/10055) (5.4  5y-impact factor), [CHI22](https://programs.sigchi.org/chi/2022/authors/72928), [ICMI21](https://dl.acm.org/doi/10.1145/3462244.3479962), [ACII19](https://acii-conf.net/2019/). My research is funded through various scholarships awards: [EPSRC](https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/S022325/1), [Google Women Techmakers](https://www.womentechmakers.com/), and [Rabin Ezra](http://rabinezrascholarship.org/).



### A few more details...
I  am funded by [EPSRC](https://epsrc.ukri.org/) through [IGGI CDT](http://www.iggi.org.uk/) to continue my PhD research. IGGI stands for Intelligent Games and Game Intelligence and it started as a Centre for Doctoral Training across 4 Universities: York University, Goldsmiths UoL, Queen Mary UoL and Essex University.

My current focus is on the nonverbal cues that influence and shape the social interaction in immersive VR environments. More broadly, I'm investigating autonomous agents (or virtual humans) in social settings in terms of non-verbal interactions with users. I'm interested in the underlying mechanics of social interaction that help developing an emphatic and engaging virtual human. At the moment, I'm working on ML models based on multimodal datasets to detect various social cues (such as gaze) or various human-defined concepts (such as engagement) in social interactions in VR. Using the same pipeline, I'm also interested in generating more complex behaviour for virtual characters (NPCs) that will improve the user's experience with the NPCs in a social VR setting.  
I have a theoretical background in Computer Science, completing with distinction an undergraduate degree in 2017. My thesis explored automatic detection of duplicate questions in community-based question answering platforms by learning semantic representation of queries.

Recently, I was awarded two scholarships, did a summer internship at MSR Cambridge, and presented at CHI22. In summer '22 I'll be at Develop, the Game AI Summer School, and IVA22. To find out more about these and others, have a look at [things I've done](./projects.html) and at [what I'm doing now](./now.html).
