# selection of projects, talks, awards
<br><br>



## Workshop at IVA2020
*October 2020*

---

## Internship at Microsoft Research with Jaron Lanier
*June 2020*

---

## Award: Google Woman Techmakers Scholarship
*April 2020*

---

## Talk at Immersive UK
*April 2020*

---

## Award: Rabin Ezra Scholarship 
*March 2020*

---

## Winner of VIVE Dev Jam
*January 2020*

![Jan20 ViveJam](/assets/img/Jan20ViveJam.png)

Or Pinky Mega team 4 (very spontaneous name, I know) won the [first prize](https://twitter.com/htcvive/status/1221865150916882433) at the VIVE developer Jam. 

The team was formed of Carlos Gonzalez Diaz(https://carlotes247.github.io/), Claire Wu, [Lili Eva Bartha](https://www.lilievabartha.com/) and myself and we put together an active listening project where the user would drive the interaction (and the discourse) using their implicit behaviour. It was a lot of fun but also long hours of work. We were very sleep deprived after the whole weekend but also happy that we got the chance to meet new people and to play with some pretty cool new toys such as the lip tracker from VIVE. Goldsmiths University of London wrote [a blog post](http://www.doc.gold.ac.uk/blog/?p=2886) about us and other Goldsmiths students who attended the Jam.

---

## Speaker at the *AI and Character Driven Immersive Experiences Workshop*
*December 2019*

![Dec19 Workshop](/assets/img/dec19workshopcombined.PNG)

I ended 2019 with a [workshop](https://sites.google.com/view/gsvr) on how immersive experiences can be driven by AI and virtual characters. As soon as I finished my internship, I start helping plan this workshop with [Sylvia Pan](https://www.panxueni.com/) and [Marco Gillies](https://www.gold.ac.uk/computing/staff/m-gillies/). It was an even that showed work from the academia (such as the work of [Prof Anthony Steed](https://wp.cs.ucl.ac.uk/anthonysteed/) or [Prof Antonia Hamilton](http://www.antoniahamilton.com/)) but also from the industry world (Royal Shakespeare Company, or HTC VIVE). 

I also had the chance to give a full presentation (and a demo) on the work I've done during my internship. It included the things I've learned and the AI tool we've developed. More on this to come, hopefully as a more polished project and with the published results. 

---
<br>


## Poster and DC at ACII19
*September 2019*

![ACII Talk](/assets/img/acii_talk.jpg)

I've been following the research presented at [ACII](http://acii-conf.org/2019/) (International Conference on
Affective Computing & Intelligent Interaction) since the start of my research journey. I'm so happy to have the chance to present some of my preliminary work as a [doctoral consortium paper](https://ieeexplore.ieee.org/document/8925113) and poster. 

I have to say, I was very nervous about presenting it, but after that, I had lots of fun attending the rest of the conference. I could see in person some of the researchers I follow a lot such as [Catherine Pelachaud](http://pages.isir.upmc.fr/~pelachaud/), [Stacy Marsella](http://stacymarsella.org/Stacy_Marsella_Homepage/Stacy_Marsella_Homepage.html), [Jonathan Gratch](https://people.ict.usc.edu/~gratch/), [Rosalind Picard](https://www.media.mit.edu/people/picard/publications/), [Daniel McDuff](http://alumni.media.mit.edu/~djmcduff/) and many others. 

There were three key-note speakers Simon Baron-Cohen, Lisa Feldman Barrett and Thomas Ploetz. All three were very insightful, however, Lisa Feldman Barrett gave a very on-point presentation on the machines perceiving emotions. [The key-note recording](https://www.youtube.com/watch?v=gPPHgeJHRF8) is on Youtube and, do have a look if you're interested in this subject. After the conference, I read her book [*How Emotions are Made*](https://lisafeldmanbarrett.com/books/how-emotions-are-made/) which was a very very good and easy-to-follow book. 


---
<br>

## Imitation Learning Workshop 
*September 2019*

![IGGI Workshop talk](/assets/img/iggi19workshop.jpg)

Along with [Carlos Gonzalez Diaz](https://carlotes247.github.io/), we organised a workshop for the annual *Intelligent Games & Game Intelligence ([IGGI](https://iggi.org.uk/)) Conference* in York, UK. We introduced the Unity3D ML-Agents platform, the algorithms that can be used within the framework with a focus on the imitation learning one: Behaviour Cloning. The attendees when through a tutorial to build a game by setting-up the ML-Agents framework, training it using Tensorflow and testing it back in the game engine. 

If you're interested, you can have a look at the [slides presented](https://docs.google.com/presentation/d/1Q7S3RcUPYF3c8m5Y22ruEv24_OBPnffpIoDStV60VY4/edit?usp=sharing) and at the [github repo](https://github.com/carlotes247/IGGI19_Imitation_Learning_Workshop) used in the workshop.

---
<br>


## Doctoral Research Intern
*Summer-Autumn 2019*

![Internship at DRI](/assets/img/DRI_working_PC.jpg)

Collaborating with two games studios ([Dream Reality Interactive](https://www.dreamrealityinteractive.com/) and [Maze Theory](https://www.maze-theory.com/)) and with the academic suport from Goldsmiths UoL, we created an immersive ML pipeline for Virtual Reality experiences, project funded by [Innovate UK](https://www.ukri.org/councils/innovate-uk/). 

The work was based on reinforcement learning an imitation learning concepts using the [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents) platform. The ML pipeline we built detects a social attitude (such as sympathy, aggression or social engagement) during an interaction in VR between the player and a non-player character. Together we conceptualised the pipeline, planed the study design, built the environment for data collection, trained & evaluated the model and part-integrated the pipeline in the final game product. 

Overall, this work introduces an immersive ML pipeline for detecting social attitudes and demonstrates how creatives could use ML and VR to expand their ability to design more engaging experiences. Here, Goldsmiths wrote [a news article](https://www.gold.ac.uk/news/peaky-blinders-vr/) about it.


---
<br>

## Teaching 3D Virtual Environments and Animation
*Spring Term 2019*

This spring term I was an associate lecturer for the VR module in Goldsmiths. Along with [Leshao Zhang](https://twitter.com/zhangleshao?lang=en), I took care of the labs, while [Sylvia Pan](https://twitter.com/panxueni) was running the lectures. I was teaching mostly basics of Unity3D for VR applications and helping students with VR projects (just imagine lots of brainstorming, troubleshooting, code debugging and testing cool(!!) VR games and applications). They came up with really cool projects, there will be a blogpost about this soon! For now have a short list of some of them: Zombie Game, Furniture assembly, Bee Simulator(short video below), Stress-relieve smashing game, Water Meditation and Immersive 3D creation and visualisation tool. Marco Gillies wrote a more in-depth [blog post on Medium](https://medium.com/virtual-reality-virtual-people/vr-masters-projects-de45175e180c) about it.

 <p><center><video src="/assets/img/bee-simulator.mp4" width="260" height="480" controls preload></video></center></p>

I hope the students benefited a lot from this module, it was very interesting for me too. It was also my first teaching experience in a university environment- nothing like teaching kids creative coding in afterschool clubs!! A few weeks ago it had a guest speaker too -[Francesco Giordana](https://twitter.com/fragiordana?lang=en) from [Moving Picture Company](https://www.mpcfilm.com/). It was incredible to see that they are using VR for film making; He described something called *Virtual Production* which lets previewing Computer-Generated (CG) elements, in real-time on a film set. It also enables the filmmakers to scout the environment, capture, add animations iterate through and shoot with virtual cameras - everything **within** the virtual environment! They had projects where all of this was done remotely too- with people from around the world.

The 3D Virtual Environments and Animation module will run again next year- I look forward to being part of this again. There's also a brand new [MA/MSc Virtual and Augmented Reality](https://www.gold.ac.uk/pg/ma-msc-virtual-augmented-reality/) that starts next September as well, if it sounds like your thing! 

---
<br>

## Virtual Social Interaction 
*December 2018*

The [4th Workshop on Virtual Social Interaction](https://sites.google.com/view/vsi2018/home) took place on 17-18 Decembre 2018 at Goldsmiths UoL. I'm glad I had the chance to attend and help organise this event. 

[Marco Gilles](http://www.doc.gold.ac.uk/~mas02mg/MarcoGillies/) wrote a nice overview of the event- have a look at his [VSI18 blogpost](https://medium.com/virtual-reality-virtual-people/virtual-social-interaction-conference-8972dcd9211c). It was indeed, such an interesting workshop across both days, featuring all female keynote speakers, a range of inspiring talks and a buzzing poster session.

If you joined the workshop and want to stay in touch (or if you want to hear updates about it + other related news) join our [VSI Google Group](https://groups.google.com/forum/embed/?place=forum/virtual-interaction)! 

Oh, and stay tuned for **VSI2020**!!

---
<br>


## W|E
*August 2018*

![W\|E project: Trabi](/assets/img/wetrabi.png)

In August 2018 I took part in this amazing one-week [Signal & Noise workshop](https://www.media.mit.edu/events/mlberlin-signalandnoise/) organised by the [MIT Media Lab](https://www.media.mit.edu/) in Berlin. The track I was part of was  *VR/AR-based learning experience* led by [Scott Greenwald](https://www.media.mit.edu/people/swgreen/projects/). 

We created, indeed, a learning experience about the Berlin Wall based on first-hand escape stories. Media Lab created this [video to showcase the behind-the-scenes process](https://youtu.be/C16gaWamXpg) of our project and Die Welt wrote [this article](https://www.welt.de/kmpkt/article181321644/MIT-Projekt-Wie-du-unter-der-Berliner-Mauer-in-den-Westen-fluechten-kannst.html) about our work! One week was enough to prototype this, but we want to put together a final product, therefore this is an on-going project now- _how exciting_! Find out more about the project and the (great!) people working on it on [W\|E website](http://we-vr.berlin/) and follow us [on Twitter](https://twitter.com/WEVR_Berlin) to see what we are up to! 

---
<br>

## VR Escape Room experience
*May 2018*

![VR Escape Room](/assets/img/vrthingy.PNG)

This is a game prototype for an escaperoom/puzzle-like experience in 6DoF VR. The aim is to exit the room by opening the main door. The main door is initially locked (shown by a red door). To unlock it, the user needs to solve a puzzle. It can be solved by finding the right objects in the room and place them on the table next to their 'trace'. The shapes on the table and the clue on the screen should help the player pick the right objects and solve the puzzle. When the right objects are placed on the table, the door gets unlocked (its colour turns green) and the player can open it and exit the room. Here's a [short overview of how the room looks like](https://www.youtube.com/watch?v=cxV6fWVhEZE).

This prototype was created by myself in Unity 3D using Oculus SDK and VRTK for the Game Development module (14/05/18 - 25/05/18).

---
<br>

## GGJ Game: QT-Labs
*Jan 2018* 

![QT-Labs](/assets/img/qtlabs.PNG)

This is a VR game created in Unity3D over a weekend during the 2018 Global Game Jam (Queen Mary UoL site). The team had six members: one sound effect & music member, two 3D and 2D artists who created and designed the game assets and three developers. I was one of the three developers, having the role of implementing the game logic and testing the game. Here's our [porject overview on GGJ website](https://globalgamejam.org/2018/games/qt-labs) and here's a [short gameplay.](https://vimeo.com/253292962)

---
<br>

## StarWing Genetica
*Nov 2017* 

![StarwingGenetica](/assets/img/starwinggenetica.PNG)

This is a game developed in Unity over the course of a 2-weeks Game Development module in Goldsmiths UoL. StarWing Genetica is a one player space-themed shooter game, partly inspired by classic arcade games. In this game, a genetic algorithm is used to evolve better enemy agents over time. [Here's a short gameplay.](https://www.youtube.com/watch?v=n4fnTExbxMs&feature=youtu.be)

It was designed and built by a team of three: Charlie Ringer, Valerio Bonametti, and myself.

---
<br>

*So what now? Maybe check out [what I'm doing now](https://cristinadobre.github.io/now.html) or see some basic stuff [about me](https://cristinadobre.github.io/)!*
